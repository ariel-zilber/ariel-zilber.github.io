<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on ariel-zilber</title>
    <link>https://ariel-zilber.github.io/posts/</link>
    <description>Recent content in Posts on ariel-zilber</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Apr 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://ariel-zilber.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Adversarial Attacks on LLMs</title>
      <link>https://ariel-zilber.github.io/posts/2023-10-25-adv-attack-llm/</link>
      <pubDate>Wed, 25 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ariel-zilber.github.io/posts/2023-10-25-adv-attack-llm/</guid>
      <description>The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.
A large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space.</description>
    </item>
    
       <item>
      <title>Transformers Inference optimizations methods</title>
      <link>https://ariel-zilber.github.io/posts/2024-17-25-transformers-efficient-inference/</link>
      <pubDate>Wed, 17 Apr 2024$ 00:00:00 +0000</pubDate>
      
      <guid>https://ariel-zilber.github.io/posts/2024-17-25-transformers-efficient-inference/</guid>
      <description>How to optimize transfoermers methods</description>
    </item>
    
   


<article class="post-entry tag-entry"> 
    <header class="entry-header">
      <h2>Transformers Inference optimizations methods
      </h2>
    </header>
    <section class="entry-content">
      <p>T....</p>
    </section>
    <footer class="entry-footer">Date: April 17, 2024  |  Estimated Reading Time: 33 min  |  Author: Ariel Zilber</footer>
    <a class="entry-link" aria-label="post link to Transformers Inference Optimization methods" href="https://ariel-zilber.github.io/posts/2024-17-25-transformers-efficient-inference/"></a>
  </article>



  </channel>
</rss>
